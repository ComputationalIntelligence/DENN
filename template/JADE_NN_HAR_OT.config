//info
var workers threads()+1, seed date("%S%H%d%m%Y")
//dataset
var
{
    validation true
    input $validation ? "datasets/har_ot_normalized.db.gz" : "datasets/har_ot_novalidation_normalized.db.gz" 
    batch 500
    batch_size $batch
    batch_offset $batch
}
//denn
var
{
    gens 8000
    sub_gens 10

    np 20
    npp -1.0
    //de params
    //co ev params
    conet_build "best"
    conet_split "matrix"
    conet_select "best"
    //selection
    crowding false
    //others
    clamp sqrt(561)
    //xavier rand
    rand 1.0 / sqrt(561)
    //LE
    crossover interm
    compute_test_per_pass false
    reval true
}
//output
var output "JADE_NN_HAR_OT.json", full_output "results/" + $output, stream "::cout"
////////////////////////////////////////////////////////
//network
network
{
    fc[50] sigmoid
    fc[]
    softmax
}

//Batch info
dataset $input
batch_size $batch_size
batch_offset $batch_offset
use_validation $validation 
compute_test_per_pass $compute_test_per_pass
reval_pop_on_batch $reval
conet_build $conet_build

conet_build $conet_build
conet_split $conet_split
conet_select $conet_select

//DE Params
evolution_method JADE 
{
    //jade params
    archive_size 0
    //mutations
    mutation  curr_p_best
    //crossover
    crossover $crossover
}

crowding_selection $crowding
generations $gens
sub_gens $sub_gens
number_parents $np
number_parents_percentage $npp

//init individuals
distribution uniform {
    uniform_min -$rand
    uniform_max  $rand
}
clamp_max  $clamp
clamp_min  -$clamp



//threads, seed, and output
threads_pop $workers
seed $seed
output $full_output
runtime_output_file $stream
